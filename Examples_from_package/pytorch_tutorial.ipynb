{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOJZf56ObYraWnJFYg/7AQv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Pytorch Function Regression Example**"],"metadata":{"id":"F6jOyRKNVZKW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iV2-Pu6eVs9v"},"outputs":[],"source":["# CPU-only PyTorch (no CUDA needed)\n","!pip -q install --upgrade pip\n","!pip -q install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cpu\n","!pip -q install tqdm"]},{"cell_type":"markdown","source":["**Importing Packages**\n","\n","This is the convention of torch packages to import.  It is recommended to print whether \"cuda\" is available and define the \"device\" for your script."],"metadata":{"id":"m71YaNswVmJJ"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset, Dataset\n","from tqdm import tqdm\n","import sys, random\n","import matplotlib.pyplot as plt\n","\n","print(\"Python:\", sys.version.split()[0])\n","print(\"torch :\", torch.__version__)\n","print(\"torchvision:\", __import__(\"torchvision\").__version__)\n","print(\"torchaudio :\", __import__(\"torchaudio\").__version__)\n","print(\"CUDA available?\", torch.cuda.is_available())\n","\n","device = torch.device(\"cpu\") # gpu device = \"cuda\"\n","print(f'{device=}')\n","\n","torch.manual_seed(0); random.seed(0); np.random.seed(0)\n","torch.set_printoptions(precision=3)"],"metadata":{"id":"jI0MxIVJsl2T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Load Data**\n","\n","Loading data, splitting into training, validation, and testing (if applicable) splits.  Must be turned into torch.tensor at some point."],"metadata":{"id":"lWtAnBfzXNMB"}},{"cell_type":"code","source":["## LOAD DATA\n","\n","def load_data():\n","  x = np.linspace(-5, 5, 1001)\n","  y = np.where(x < 2.5,\n","             np.sin(np.exp(0.8*x)) * np.exp(-0.3*x),\n","             (-1/2.5)*x + 1.5) + np.random.randn(len(x)) * 0.1\n","  y_fun = np.where(x < 2.5,\n","             np.sin(np.exp(0.8*x)) * np.exp(-0.3*x),\n","             (-1/2.5)*x + 1.5)\n","  # validation split is (-3, -2.5) and (4, 4.5), everythin else is training split\n","  indices = list(range(len(x)))\n","  train_indices = indices[:200] + indices[250:900] + indices[950:]\n","  val_indices = indices[200:250] + indices[900:950]\n","  test_indices = indices[750:900]\n","  x_train = x[train_indices]\n","  y_train = y[train_indices]\n","  x_val = x[val_indices]\n","  y_val = y[val_indices]\n","  return x_train, y_train, x_val, y_val\n"],"metadata":{"id":"WOls_7H_s3pL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train, y_train, x_val, y_val = load_data()\n","\n","x = np.linspace(-5, 5, 1001)\n","y_fun = np.where(x < 2.5,\n","             np.sin(np.exp(0.8*x)) * np.exp(-0.3*x),\n","             (-1/2.5)*x + 1.5)\n","plt.scatter(x_train, y_train, color='green', s=4, label='Training data')\n","plt.scatter(x_val, y_val, color='blue', s=4, label='Validation data')\n","plt.plot(x, y_fun, color='black', linewidth=2, label='True function') # black\n","plt.legend()\n","plt.show()"],"metadata":{"id":"pPFoiePMy7wx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Dataset Class**\n","\n","Understanding the dataset class is crucial to train models in bespoke applications.  This class only requires the __len and __getitem methods.  This class takes your input and output and zips them together for your dataloader.  While there is an importable module for this (it is just the following code), keeping this section in your script allows more complex operations on your input and output.  Within getitem, you can modify your data on the fly if it is undesirable to load it initially."],"metadata":{"id":"Fw3XoY4yXgQL"}},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, inputs,  targets):\n","        self.inputs = inputs\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, idx):\n","        inputs = self.inputs[idx]\n","        target = self.targets[idx]\n","        return inputs, target"],"metadata":{"id":"wcCBs0G6y99y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Dataloaders**\n","\n","Dataloaders take your dataset as an input, batch it, and return batches of your input, output pairs as singular tensors."],"metadata":{"id":"eoarr6UzYfPo"}},{"cell_type":"code","source":["x_train = torch.from_numpy(x_train).float()\n","y_train = torch.from_numpy(y_train).float()\n","x_val = torch.from_numpy(x_val).float()\n","y_val = torch.from_numpy(y_val).float()\n","\n","train_dataset = CustomDataset(x_train, y_train)\n","val_dataset = CustomDataset(x_val, y_val)\n","train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size=10, shuffle=True, drop_last=True)"],"metadata":{"id":"I-AJSVGYlZSz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_dataset[100])\n","for input, target in train_loader:\n","  print(input, target)\n","  break"],"metadata":{"id":"TeqI_S7nmUPZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Training Loop**"],"metadata":{"id":"im_ed9CEYwcN"}},{"cell_type":"code","source":["def train_epoch(dataloader, model, optimizer, loss_function, device):\n","    model.train()\n","    total_loss = 0\n","    for inputs, targets in dataloader:\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","        optimizer.zero_grad()\n","        predictions = model(inputs)\n","        loss = loss_function(predictions, targets)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","\n","def validate_epoch(dataloader, model, loss_function, device):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for inputs, targets in dataloader:\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","            predictions = model(inputs)\n","            loss = 0\n","            loss = loss_function(predictions, targets)\n","            total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","def train_and_validate(epochs, model, optimizer, loss_function, train_loader, val_loader, device):\n","\n","    model.to(device)  # Move model to the appropriate device\n","    for epoch in range(epochs):\n","        # print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n","        train_loss = train_epoch(train_loader, model, optimizer, loss_function, device)\n","        val_loss = validate_epoch(val_loader, model, loss_function, device)\n","        print(f\"Epoch {epoch + 1} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")"],"metadata":{"id":"PAFmCj6QmgkA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Definition**"],"metadata":{"id":"WtI8tKhBY8ym"}},{"cell_type":"code","source":["class ModelExample(nn.Module):\n","    def __init__(self):\n","        super(ModelExample, self).__init__()\n","\n","        # Define deeper convolutional layers\n","        self.lin1 = nn.Linear(1, 16)\n","        self.lin2 = nn.Linear(16,16)\n","        self.lin3 = nn.Linear(16,16)\n","        self.lin4 = nn.Linear(16,1)\n","        self.sig = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.lin1(x)\n","        x = self.sig(x)\n","        x = self.lin2(x)\n","        x = self.sig(x)\n","        x = self.lin3(x)\n","        x = self.sig(x)\n","        x = self.lin4(x)\n","        x = self.sig(x)\n","        return x"],"metadata":{"id":"Ii5l_5Y5sonp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Define Instance of Model, the optimizer, and the loss function**"],"metadata":{"id":"nGOgB-8pY_bv"}},{"cell_type":"code","source":["# Define Model Instance\n","model = ModelExample()\n","\n","# Load Optimizer and Loss Function\n","optimizer = optim.Adam(model.parameters(), lr=0.1)\n","loss_function = nn.MSELoss()"],"metadata":{"id":"TB29Xyrrraq0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_and_validate(30, model, optimizer, loss_function, train_loader, val_loader, device)"],"metadata":{"id":"JJSVEbsMsmuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ModelExample(nn.Module):\n","    def __init__(self, embed_dim):\n","        super(ModelExample, self).__init__()\n","\n","        # Define deeper convolutional layers\n","        self.lin1 = nn.Linear(1, embed_dim)\n","        self.lin2 = nn.Linear(embed_dim, embed_dim)\n","        self.lin3 = nn.Linear(embed_dim,embed_dim)\n","        self.lin4 = nn.Linear(embed_dim,embed_dim)\n","        self.lin5 = nn.Linear(embed_dim,1)\n","        self.sig = nn.ReLU() # nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","        x = self.lin1(x)\n","        x = self.sig(x)\n","        x = self.lin2(x)\n","        x = self.sig(x)\n","        x = self.lin3(x)\n","        x = self.sig(x)\n","        x = self.lin4(x)\n","        x = self.sig(x)\n","        x = self.lin5(x)\n","        return x.squeeze()\n","\n","# Define Model Instance\n","model = ModelExample(15)\n","\n","# Count model Parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Total Parameters: {total_params}\")\n","\n","# Load Optimizer and Loss Function\n","optimizer = optim.Adam(model.parameters(), lr=0.0012)\n","loss_function = nn.MSELoss()\n","\n","train_and_validate(30, model, optimizer, loss_function, train_loader, val_loader, device)"],"metadata":{"id":"JHZmSiT5wo7U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = np.linspace(-5, 5, 1001)\n","y_pred = model(torch.Tensor(x).unsqueeze(1))\n","y_pred = y_pred.detach().numpy()\n","y_fun = np.where(x < 2.5,\n","             np.sin(np.exp(0.8*x)) * np.exp(-0.3*x),\n","             (-1/2.5)*x + 1.5)\n","plt.scatter(x, y_pred, color='green', s=4, label='Model Predictions')\n","plt.plot(x, y_fun, color='black', linewidth=2, label='True function') # black\n","# plot vertical lines at -3, -2.5, 4, 4.5\n","plt.axvline(x=-3, color='red', linestyle='--')\n","plt.axvline(x=-2.5, color='red', linestyle='--')\n","plt.axvline(x=4, color='red', linestyle='--')\n","plt.axvline(x=4.5, color='red', linestyle='--')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"X7TbmuSvxZAX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## LOAD DATA\n","# our function is y = sin(e^(0.8x))e^(-0.3x) + noise\n","def load_data_50():\n","  x = np.linspace(-5, 5, 51)\n","  y = np.where(x < 2.5,\n","             np.sin(np.exp(0.8*x)) * np.exp(-0.3*x),\n","             (-1/2.5)*x + 1.5) + np.random.randn(len(x)) * 0.1\n","  y_fun = np.where(x < 2.5,\n","             np.sin(np.exp(0.8*x)) * np.exp(-0.3*x),\n","             (-1/2.5)*x + 1.5)\n","  # validation split is (-3, -2.5) and (4, 4.5), everythin else is training split\n","  indices = list(range(len(x)))\n","  train_indices = indices[:10] + indices[13:45] + indices[48:]\n","  val_indices = indices[10:13] + indices[45:48]\n","  x_train = x[train_indices]\n","  y_train = y[train_indices]\n","  x_val = x[val_indices]\n","  y_val = y[val_indices]\n","  return x_train, y_train, x_val, y_val\n","\n","x_train, y_train, x_val, y_val = load_data_50()\n","\n","x = np.linspace(-5, 5, 1001)\n","# y_fun = np.sin(np.exp(0.8*x)) * np.exp(-0.3 * x)\n","y_fun = np.where(x < 2.5,\n","             np.sin(np.exp(0.8*x)) * np.exp(-0.3*x),\n","             (-1/2.5)*x + 1.5)\n","plt.scatter(x_train, y_train, color='green', s=4, label='Training data')\n","plt.scatter(x_val, y_val, color='blue', s=4, label='Validation data')\n","plt.plot(x, y_fun, color='black', linewidth=2, label='True function') # black\n","plt.legend()\n","plt.show()"],"metadata":{"id":"xmx6yUYN0pgK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = torch.from_numpy(x_train).float()\n","y_train = torch.from_numpy(y_train).float()\n","x_val = torch.from_numpy(x_val).float()\n","y_val = torch.from_numpy(y_val).float()\n","\n","train_dataset = CustomDataset(x_train, y_train)\n","val_dataset = CustomDataset(x_val, y_val)\n","train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, drop_last=True)"],"metadata":{"id":"svfJ6guwQy7x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Define Model Instance\n","model = ModelExample(100)\n","\n","# Count model Parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Total Parameters: {total_params}\")\n","\n","# Load Optimizer and Loss Function\n","optimizer = optim.Adam(model.parameters(), lr=0.0012)\n","loss_function = nn.MSELoss()\n","\n","train_and_validate(400, model, optimizer, loss_function, train_loader, val_loader, device)"],"metadata":{"id":"NryW5zsmO7cn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = np.linspace(-5, 5, 1001)\n","y_pred = model(torch.Tensor(x).unsqueeze(1))\n","y_pred = y_pred.detach().numpy()\n","y_fun = np.where(x < 2.5,\n","             np.sin(np.exp(0.8*x)) * np.exp(-0.3*x),\n","             (-1/2.5)*x + 1.5)\n","plt.scatter(x, y_pred, color='green', s=4, label='Model Predictions')\n","plt.scatter(x_train, y_train, color='blue', s=4, label='Data')\n","plt.plot(x, y_fun, color='black', linewidth=2, label='True function') # black\n","# plot vertical lines at -3, -2.5, 4, 4.5\n","plt.axvline(x=-3, color='red', linestyle='--')\n","plt.axvline(x=-2.5, color='red', linestyle='--')\n","plt.axvline(x=4, color='red', linestyle='--')\n","plt.axvline(x=4.5, color='red', linestyle='--')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"0_EScnGkPt8X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Custom Loss Function**\n","\n","You can define a custom loss function as a normal function, or you can use the nn.Module if you need class-based functionality.  In the latter case, your function itself goes under \"forward\"."],"metadata":{"id":"Iecg9rFGZH9f"}},{"cell_type":"code","source":["# Run with custom loss function.  If prediction is above our data up to 0.1 above, we do not penalize\n","# We can do this with a normal function, or you can use the nn.Module if you need class-based functionality\n","def custom_loss(y_pred, y_true):\n","    x = y_pred - y_true\n","    loss = (torch.clamp(-x, min=0))**2 + (torch.clamp(x - 0.2, min=0))**2\n","    return torch.mean(loss)\n","\n","x_train, y_train, x_val, y_val = load_data()\n","\n","x_train = torch.from_numpy(x_train).float()\n","y_train = torch.from_numpy(y_train).float()\n","x_val = torch.from_numpy(x_val).float()\n","y_val = torch.from_numpy(y_val).float()\n","\n","train_dataset = CustomDataset(x_train, y_train)\n","val_dataset = CustomDataset(x_val, y_val)\n","train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, drop_last=True)\n","\n","\n","# Define Model Instance\n","model = ModelExample(15)\n","\n","# Count model Parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Total Parameters: {total_params}\")\n","\n","# Load Optimizer and Loss Function\n","optimizer = optim.Adam(model.parameters(), lr=0.0012)\n","loss_function = custom_loss\n","\n","train_and_validate(30, model, optimizer, loss_function, train_loader, val_loader, device)"],"metadata":{"id":"AfPQ5rfVQRzR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = np.linspace(-5, 5, 1001)\n","y_pred = model(torch.Tensor(x).unsqueeze(1))\n","y_pred = y_pred.detach().numpy()\n","y_fun = np.where(x < 2.5,\n","             np.sin(np.exp(0.8*x)) * np.exp(-0.3*x),\n","             (-1/2.5)*x + 1.5)\n","plt.scatter(x, y_pred, color='green', s=4, label='Model Predictions')\n","plt.scatter(x_train, y_train, color='blue', s=4, label='Data')\n","plt.scatter(x_val, y_val, color='red', s=4, label='Data')\n","plt.plot(x, y_fun, color='black', linewidth=2, label='True function') # black\n","# plot vertical lines at -3, -2.5, 4, 4.5\n","plt.axvline(x=-3, color='red', linestyle='--')\n","plt.axvline(x=-2.5, color='red', linestyle='--')\n","plt.axvline(x=4, color='red', linestyle='--')\n","plt.axvline(x=4.5, color='red', linestyle='--')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"gov-F7rinuCK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Other Functionality**\n","\n","\n","\n","1.   Print the gradients\n","2.   Freeze certain layers of the model\n","3.   Save and load checkpoints\n","\n"],"metadata":{"id":"vWh_xdZ2ZbKh"}},{"cell_type":"code","source":[],"metadata":{"id":"9W5brvR_ZsL9"},"execution_count":null,"outputs":[]}]}